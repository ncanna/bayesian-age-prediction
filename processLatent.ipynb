{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "processLatent.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4Xl-MxJTj9bV",
        "tdpMZyyMh6GZ"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Combine data set"
      ],
      "metadata": {
        "id": "wruEtO8w2erZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YNL9DuJKYb9",
        "outputId": "17fe5483-7eea-41b2-a043-fbb071024295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l '/gdrive/MyDrive/Bayesian Learning Final Project/Submission/NN_model'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbkqfbulgXZ9",
        "outputId": "96c01be7-1b83-4783-8460-f0e64831c900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1224738\n",
            "-rw------- 1 root root     24908 Dec  9 19:03  DataCombine.ipynb\n",
            "-rw------- 1 root root    122662 Nov 30 14:08 'model result.png'\n",
            "-rw------- 1 root root    497182 Dec  9 18:26  pca_latent_train_50.csv\n",
            "-rw------- 1 root root    150533 Dec  8 19:03  pca_latent_train.csv\n",
            "-rw------- 1 root root     55957 Dec  9 18:26  pca_latent_val_50.csv\n",
            "-rw------- 1 root root     16897 Dec  8 19:03  pca_latent_val.csv\n",
            "-rw------- 1 root root     75368 Dec  8 22:33  tn_combined2.npy\n",
            "-rw------- 1 root root    221888 Dec  9 18:51  tn_combined_50.npy\n",
            "-rw------- 1 root root      4200 Nov 30 14:10  tnKeys.npy\n",
            "-rw------- 1 root root   1019161 Nov 30 14:10  torchModel\n",
            "-rw------- 1 root root 562913408 Dec  8 02:22  train_latent.npy\n",
            "-rw------- 1 root root 562913408 Nov 30 14:10  train.npy\n",
            "-rw------- 1 root root      8640 Dec  8 22:33  val_combined2.npy\n",
            "-rw------- 1 root root     25216 Dec  9 18:51  val_combined_50.npy\n",
            "-rw------- 1 root root  63037568 Dec  8 02:22  validation_latent.npy\n",
            "-rw------- 1 root root       584 Nov 30 14:10  valKeys.npy\n",
            "-rw------- 1 root root  63037568 Nov 30 14:10  val.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_root = '/gdrive/MyDrive/Bayesian Learning Final Project/Submission/NN_model'"
      ],
      "metadata": {
        "id": "8GhGWknEhEDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# load feature vector after PCA (TN)\n",
        "# tn_feat = pd.read_csv( '/gdrive/MyDrive/UVA/DS6040/Project3/Copy of pca_latent_train.csv' )\n",
        "# tn_feat = pd.read_csv( os.path.join( data_root, 'pca_latent_train_50.csv' ) )\n",
        "tn_feat = pd.read_csv( os.path.join( data_root, 'pca_latent_train.csv' ) )\n",
        "tn_feat = np.array(tn_feat)\n",
        "tn_feat = tn_feat[:, 1:]\n",
        "\n",
        "# load feature vector after PCA (VAL)\n",
        "# val_feat = pd.read_csv( '/gdrive/MyDrive/UVA/DS6040/Project3/Copy of pca_latent_val.csv' )\n",
        "# val_feat = pd.read_csv( os.path.join( data_root, 'pca_latent_val_50.csv' ) )\n",
        "val_feat = pd.read_csv( os.path.join( data_root, 'pca_latent_val.csv' ) )\n",
        "val_feat = np.array(val_feat)\n",
        "val_feat = val_feat[:, 1:]\n",
        "\n",
        "print( tn_feat.shape, val_feat.shape ) \n",
        "\n",
        "# load case keys for TN and VAL \n",
        "tn_key = np.load( '/gdrive/MyDrive/UVA/DS6040/Project3/tnKeys.npy' )\n",
        "val_key = np.load( '/gdrive/MyDrive/UVA/DS6040/Project3/valKeys.npy' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fot382wQ2ggn",
        "outputId": "c251b700-266d-4fa7-e459-cdb2319b7e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(509, 15) (57, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download demographic file\n",
        "!wget http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI.xls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfyFseaS_2rf",
        "outputId": "cf7917f4-5a55-42e0-cc06-1505af99c1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-09 19:26:43--  http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI.xls\n",
            "Resolving biomedic.doc.ic.ac.uk (biomedic.doc.ic.ac.uk)... 146.169.22.31\n",
            "Connecting to biomedic.doc.ic.ac.uk (biomedic.doc.ic.ac.uk)|146.169.22.31|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI.xls [following]\n",
            "--2021-12-09 19:26:43--  https://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI.xls\n",
            "Connecting to biomedic.doc.ic.ac.uk (biomedic.doc.ic.ac.uk)|146.169.22.31|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 210432 (206K) [application/vnd.ms-excel]\n",
            "Saving to: ‘IXI.xls’\n",
            "\n",
            "IXI.xls             100%[===================>] 205.50K   774KB/s    in 0.3s    \n",
            "\n",
            "2021-12-09 19:26:44 (774 KB/s) - ‘IXI.xls’ saved [210432/210432]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo_pd = pd.read_excel( 'IXI.xls' )\n",
        "demo = np.array(demo_pd)\n",
        "print( demo_pd.columns) \n",
        "print( demo[0, :] ) "
      ],
      "metadata": {
        "id": "ebld6CtzAa7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ed1dae-d558-4f1b-a412-1a6f2fa15877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['IXI_ID', 'SEX_ID (1=m, 2=f)', 'HEIGHT', 'WEIGHT', 'ETHNIC_ID',\n",
            "       'MARITAL_ID', 'OCCUPATION_ID', 'QUALIFICATION_ID', 'DOB',\n",
            "       'DATE_AVAILABLE', 'STUDY_DATE', 'AGE'],\n",
            "      dtype='object')\n",
            "[1 1 170 80 2 3 5 2 '1968-02-22' 0 NaT nan]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numFeat = 6\n",
        "tn_trim = np.zeros( (len(tn_key), numFeat) )\n",
        "\n",
        "for idx, tn_idx in enumerate(tn_key):\n",
        "  search = np.where( demo[:, 0] == tn_idx )[0]\n",
        "  if len(search) == 0:\n",
        "    print( tn_idx, 'not found' )\n",
        "    continue\n",
        "  \n",
        "  demo_idx = search[0]\n",
        "  tn_trim[idx, 0] = int(demo[demo_idx, 0])    # case ID\n",
        "  tn_trim[idx, 1] = demo[demo_idx,2]          # height\n",
        "  tn_trim[idx, 2] = demo[demo_idx,3]          # weight\n",
        "  tn_trim[idx, 3] = 1 if demo[demo_idx,1] == 1 else 0 # male\n",
        "  tn_trim[idx, 4] = 1 if demo[demo_idx,1] == 2 else 0 # female\n",
        "  tn_trim[idx, -1] = demo[demo_idx, -1]       # age\n",
        "    \n",
        "# remove not-found cases\n",
        "print()\n",
        "na_idx = np.where(tn_trim[:, 0] == 0.0)[0]\n",
        "print( 'There are', len(na_idx), 'cases not found demographics')\n",
        "print( tn_trim.shape ) \n",
        "tn_trim = np.delete( tn_trim, np.where(tn_trim[:,0] == 0.0 )[0], 0 )\n",
        "print( tn_trim.shape ) \n",
        "\n",
        "tn_combined = np.zeros( (len(tn_trim), tn_feat.shape[-1] + numFeat) )\n",
        "tn_feat_trim = np.delete( tn_feat, na_idx, 0 )\n",
        "print( tn_feat_trim.shape ) \n",
        "\n",
        "tn_combined[:, :numFeat] = tn_trim\n",
        "tn_combined[:, numFeat:] = tn_feat_trim\n",
        "\n",
        "print( tn_combined.shape ) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktRbPwjpB79L",
        "outputId": "5d1803c6-6450-4e6e-fb35-ba3b281acd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "337 not found\n",
            "88 not found\n",
            "333 not found\n",
            "638 not found\n",
            "637 not found\n",
            "340 not found\n",
            "347 not found\n",
            "457 not found\n",
            "661 not found\n",
            "589 not found\n",
            "228 not found\n",
            "345 not found\n",
            "643 not found\n",
            "117 not found\n",
            "\n",
            "There are 14 cases not found demographics\n",
            "(509, 6)\n",
            "(495, 6)\n",
            "(495, 15)\n",
            "(495, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numFeat = 6\n",
        "val_trim = np.zeros( (len(val_key), numFeat) )\n",
        "\n",
        "for idx, val_idx in enumerate(val_key):\n",
        "  search = np.where( demo[:, 0] == val_idx )[0]\n",
        "  if len(search) == 0:\n",
        "    print( val_idx, 'not found' )\n",
        "    continue\n",
        "  \n",
        "  demo_idx = search[0]\n",
        "  val_trim[idx, 0] = int(demo[demo_idx, 0])   # case ID\n",
        "  val_trim[idx, 1] = demo[demo_idx,2]         # height\n",
        "  val_trim[idx, 2] = demo[demo_idx,3]         # weight\n",
        "  val_trim[idx, 3] = 1 if demo[demo_idx,1] == 1 else 0 # male\n",
        "  val_trim[idx, 4] = 1 if demo[demo_idx,1] == 2 else 0 # female\n",
        "  val_trim[idx, -1] = demo[demo_idx, -1]      # age\n",
        "\n",
        "print()\n",
        "na_idx = np.where(val_trim[:, 0] == 0.0)[0]\n",
        "print( 'There are', len(na_idx), 'cases not found demographics')\n",
        "print( val_trim.shape ) \n",
        "val_trim = np.delete( val_trim, np.where(val_trim[:,0] == 0.0 )[0], 0 )\n",
        "print( val_trim.shape ) \n",
        "\n",
        "val_combined = np.zeros( (len(val_trim), val_feat.shape[-1] + numFeat) )\n",
        "val_feat_trim = np.delete( val_feat, na_idx, 0 )\n",
        "print( val_feat_trim.shape ) \n",
        "\n",
        "val_combined[:, :numFeat] = val_trim\n",
        "val_combined[:, numFeat:] = val_feat_trim\n",
        "\n",
        "print()\n",
        "print( val_feat_trim.shape )\n",
        "print( val_trim.shape ) \n",
        "print( val_combined.shape ) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXa9nFcBHmlT",
        "outputId": "a54f774e-169e-43af-ed0e-f488fde30970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81 not found\n",
            "\n",
            "There are 1 cases not found demographics\n",
            "(57, 6)\n",
            "(56, 6)\n",
            "(56, 15)\n",
            "\n",
            "(56, 15)\n",
            "(56, 6)\n",
            "(56, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "print( tn_combined[0] ) \n",
        "print( val_combined[2] ) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USMqYk7CGkFb",
        "outputId": "5c90b53b-b1d6-486f-92ad-cbef29945143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[474.         152.          60.           0.           1.\n",
            "  34.01232033   0.69046307   0.43636262   0.31191289   2.04442406\n",
            "   0.17233321   0.02199122   0.2788367    0.08765933   1.33996332\n",
            "   0.4109689    0.40912798   0.06644195   1.08072746   0.74135166\n",
            "   0.29994893]\n",
            "[ 30.         180.          65.           1.           0.\n",
            "  31.46064339   1.49907458   0.41242835   0.29374197   0.21694574\n",
            "   0.21122634   0.03780565   0.46780473   0.21103936   0.81810081\n",
            "   0.16353075   0.5662201    0.51401091   1.31128001   0.06724804\n",
            "   0.10746945]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( tn_combined.shape, val_combined.shape ) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4YB_mPdG__T",
        "outputId": "62d6df9f-847e-4adf-ff92-945fcea76b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(495, 21) (56, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "m6QSdSDpqusk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.save( '/gdrive/MyDrive/UVA/DS6040/Project3/tn_combined_50.npy', tn_combined )\n",
        "# np.save( '/gdrive/MyDrive/UVA/DS6040/Project3/val_combined_50.npy', val_combined )\n",
        "\n",
        "# np.save( os.path.join( data_root, 'tn_combined_50.npy'), tn_combined)\n",
        "# np.save( os.path.join( data_root, 'val_combined_50.npy'), val_combined)\n",
        "np.save( os.path.join( data_root, 'tn_combined_sex.npy'), tn_combined)\n",
        "np.save( os.path.join( data_root, 'val_combined_sex.npy'), val_combined)"
      ],
      "metadata": {
        "id": "j8_hBiCZHACh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l '/gdrive/MyDrive/Bayesian Learning Final Project/Submission/NN_model'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23RYjReiiOpY",
        "outputId": "0291e34d-5324-4f05-c0fd-0ab2b166a64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1224736\n",
            "-rw------- 1 root root     22972 Dec  9 18:51  DataCombine.ipynb\n",
            "-rw------- 1 root root    122662 Nov 30 14:08 'model result.png'\n",
            "-rw------- 1 root root    497182 Dec  9 18:26  pca_latent_train_50.csv\n",
            "-rw------- 1 root root    150533 Dec  8 19:03  pca_latent_train.csv\n",
            "-rw------- 1 root root     55957 Dec  9 18:26  pca_latent_val_50.csv\n",
            "-rw------- 1 root root     16897 Dec  8 19:03  pca_latent_val.csv\n",
            "-rw------- 1 root root     75368 Dec  8 22:33  tn_combined2.npy\n",
            "-rw------- 1 root root    221888 Dec  9 18:51  tn_combined_50.npy\n",
            "-rw------- 1 root root      4200 Nov 30 14:10  tnKeys.npy\n",
            "-rw------- 1 root root   1019161 Nov 30 14:10  torchModel\n",
            "-rw------- 1 root root 562913408 Dec  8 02:22  train_latent.npy\n",
            "-rw------- 1 root root 562913408 Nov 30 14:10  train.npy\n",
            "-rw------- 1 root root      8640 Dec  8 22:33  val_combined2.npy\n",
            "-rw------- 1 root root     25216 Dec  9 18:51  val_combined_50.npy\n",
            "-rw------- 1 root root  63037568 Dec  8 02:22  validation_latent.npy\n",
            "-rw------- 1 root root       584 Nov 30 14:10  valKeys.npy\n",
            "-rw------- 1 root root  63037568 Nov 30 14:10  val.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Xl-MxJTj9bV"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "7c9e9230607949439f93cb5a7aecc996",
            "3c4046de306a4f72a8cea26d30b805b9"
          ]
        },
        "id": "bc_0D-S6DLnB",
        "outputId": "b89226ca-a44e-492e-fcaa-02842a0fceb5"
      },
      "source": [
        "import torchio as tio\n",
        "tf = [tio.ToCanonical(), tio.Resample((1,1,1))]\n",
        "\n",
        "ixi_dataset = tio.datasets.IXI(\n",
        "    './ixiDataset', \n",
        "    modalities=('T1', 'T2'), \n",
        "    transform=tio.Compose(tf), \n",
        "    download=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-T1.tar to /tmp/tmp6l9gnn92.tar\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c9e9230607949439f93cb5a7aecc996",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-T2.tar to /tmp/tmp9wuc5ttr.tar\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c4046de306a4f72a8cea26d30b805b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W44K-HLkQcv3"
      },
      "source": [
        "def rotate(image, radiological=True):\n",
        "    # Rotate for visualization purposes\n",
        "    image = np.rot90(image, 1)\n",
        "    if radiological:\n",
        "        image = np.fliplr(image)\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgEYk7FeNFLF"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "img = ixi_dataset[0].T1\n",
        "data = img.data[-1]\n",
        "indices = np.array( data.shape ) // 2\n",
        "i, j, k = indices\n",
        "slice_x = rotate( data[i, :, :], radiological=True )\n",
        "slice_y = rotate( data[:, j, :], radiological=True )\n",
        "slice_z = rotate( data[:, :, k], radiological=True )\n",
        "\n",
        "sr, sa, ss = img.spacing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSQGonpSR-0p"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# sagital view\n",
        "# for i in range(data.shape[0] ):\n",
        "#   plt.figure( figsize=(5, 5) ) \n",
        "#   plt.imshow( np.rot90(data[i, :, :], 1), cmap='gray' )\n",
        "#   plt.axis('off')\n",
        "\n",
        "# # cor view\n",
        "# for i in range(data.shape[1] ):\n",
        "#   plt.figure( figsize=(5, 5) ) \n",
        "#   plt.imshow( np.rot90(data[:, i, :], 1), cmap='gray' )\n",
        "#   plt.axis('off')\n",
        "\n",
        "# # axial view\n",
        "for i in range(data.shape[2] ):\n",
        "  plt.figure( figsize=(5, 5) ) \n",
        "  plt.imshow( np.rot90(data[:, :, i], 1), cmap='gray' )\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdpMZyyMh6GZ"
      },
      "source": [
        "# Model development"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flb6gMYch89t",
        "outputId": "bca6a20c-c029-4099-e3fb-7d1ef06c1abe"
      },
      "source": [
        "!pip install torchio\n",
        "!apt -qq install tree"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchio in /usr/local/lib/python3.7/dist-packages (0.18.61)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torchio) (1.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from torchio) (7.1.2)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (from torchio) (0.5.1)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.7/dist-packages (from torchio) (1.9.0+cu111)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from torchio) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from torchio) (1.19.5)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.7/dist-packages (from torchio) (1.2.13)\n",
            "Requirement already satisfied: SimpleITK!=2.0.* in /usr/local/lib/python3.7/dist-packages (from torchio) (2.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchio) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1->torchio) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated->torchio) (1.12.1)\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 40.7 kB of archives.\n",
            "After this operation, 105 kB of additional disk space will be used.\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 155047 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1082XM0iC2O"
      },
      "source": [
        "import enum\n",
        "import time\n",
        "import random\n",
        "import multiprocessing\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchio as tio\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "# from unet import UNet\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython import display\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka_kY8bZh7Mj"
      },
      "source": [
        "# Dataset\n",
        "dataset_url = 'https://www.dropbox.com/s/ogxjwjxdv5mieah/ixi_tiny.zip?dl=0'\n",
        "dataset_path = 'ixi_tiny.zip'\n",
        "dataset_dir_name = 'ixi_tiny'\n",
        "dataset_dir = Path(dataset_dir_name)\n",
        "histogram_landmarks_path = 'landmarks.npy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_EAt5dOiMT9",
        "outputId": "4ca2f899-a2d0-4ece-fcd2-c20cbdc86e0e"
      },
      "source": [
        "if not dataset_dir.is_dir():\n",
        "    !curl --silent --output {dataset_path} --location {dataset_url} \n",
        "    !unzip -qq {dataset_path}\n",
        "!tree -d {dataset_dir_name}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ixi_tiny\n",
            "├── image\n",
            "└── label\n",
            "\n",
            "2 directories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJk9Xw0aiMXF",
        "outputId": "188df549-02b5-4bd1-af0b-52c82002727c"
      },
      "source": [
        "images_dir = dataset_dir / 'image'\n",
        "labels_dir = dataset_dir / 'label'\n",
        "image_paths = sorted(images_dir.glob('*.nii.gz'))\n",
        "label_paths = sorted(labels_dir.glob('*.nii.gz'))\n",
        "assert len(image_paths) == len(label_paths)\n",
        "\n",
        "subjects = []\n",
        "for (image_path, label_path) in zip(image_paths, label_paths):\n",
        "    subject = tio.Subject(\n",
        "        mri=tio.ScalarImage(image_path),\n",
        "        brain=tio.LabelMap(label_path),\n",
        "    )\n",
        "    subjects.append(subject)\n",
        "dataset = tio.SubjectsDataset(subjects)\n",
        "print('Dataset size:', len(dataset), 'subjects')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size: 566 subjects\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_R-jdzCjT2d",
        "outputId": "bed45e86-4f9b-4d55-cfe5-8a1473eb7796"
      },
      "source": [
        "dataset[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Subject(Keys: ('mri', 'brain'); images: 2)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czkydpbjiMZ5"
      },
      "source": [
        "training_loader = torch.utils.data.DataLoader(dataset, batch_size=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRq66tL9jK7J",
        "outputId": "2de6ecd1-023f-4195-8b66-a56764b57d25"
      },
      "source": [
        "for subjects_batch in training_loader:\n",
        "    inputs = subjects_batch['mri'][tio.DATA]\n",
        "    target = subjects_batch['brain'][tio.DATA]\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ]
    }
  ]
}